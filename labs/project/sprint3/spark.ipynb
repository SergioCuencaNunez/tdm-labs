{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0942fa",
   "metadata": {},
   "source": [
    "#  <span style=\"font-family: Latin Modern Roman; font-size: 35px; font-weight: bold;\"> TradeData Project: Spark</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c69468",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e1934",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Latin Modern Roman; font-size: 25px;\"> Sprint 3 (Historias de Usuario  4) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1ee035-a97b-457b-828f-3a92c567d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bcceb9-d27b-4fde-b66f-ce086f30bde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "conf = (SparkConf()\n",
    "            .setMaster(\"yarn\")\n",
    "            .set(\"spark.executor.cores\", 5)\n",
    "            .set(\"spark.sql.shuffle.partitions\", 200)\n",
    "            .set(\"spark.default.parallelism\", 200)\n",
    "            .set(\"spark.executor.memory\", \"7g\")\n",
    "            .set(\"spark.dynamicAllocation.maxExecutors\", 20)\n",
    "        )\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf = conf) \\\n",
    "    .appName(\"Spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373bcc7f",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Latin Modern Roman; font-size: 23px;\"> Silver Layer </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d581f5c9-dad7-43ed-a54e-0f9bb1657891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver Layer Completed\n"
     ]
    }
   ],
   "source": [
    "cryptos = [\n",
    "    \"BTCUSDT\", \"ETHUSDT\", \"XRPUSDT\", \"SOLUSDT\", \n",
    "    \"DOGEUSDT\", \"ADAUSDT\", \"SHIBUSDT\", \"DOTUSDT\", \n",
    "    \"AAVEUSDT\", \"XLMUSDT\"\n",
    "]\n",
    "\n",
    "for symbol in cryptos:\n",
    "    # Load data from HDFS\n",
    "    df = spark.read \\\n",
    "              .option(\"header\", \"true\") \\\n",
    "              .option(\"inferSchema\", \"true\") \\\n",
    "              .csv(f\"/datos/gittba/gittba04/{symbol}\")\n",
    "\n",
    "    # Transform to Parquet and Load to HDFS again\n",
    "    df.write.mode(\"overwrite\").partitionBy(\"year\").parquet(f\"/datos/gittba/gittba04/{symbol}_Silver\")\n",
    "\n",
    "print(\"Silver Layer Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268b78b",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Latin Modern Roman; font-size: 23px;\"> Gold Layer </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c815f47-25a8-4965-9d89-fb95e11eb649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Layer Completed\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg, lit, lag, when, expr, year\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "\n",
    "for symbol in cryptos:\n",
    "    for year_value in years:\n",
    "\n",
    "        df_current = spark.read.parquet(f\"/datos/gittba/gittba04/{symbol}_Silver/year={year_value}\")\n",
    "        if year_value > 2021:\n",
    "            try:\n",
    "                df_previous = spark.read.parquet(f\"/datos/gittba/gittba04/{symbol}_Silver/year={year_value-1}\")\n",
    "                df_previous = df_previous.orderBy(col(\"date\").desc()).limit(200)  # Keep only the last 200 days\n",
    "                df = df_previous.union(df_current)  # Merge previous & current year data\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load previous year's data for {symbol} {year_value}: {e}\")\n",
    "                df = df_current\n",
    "        else:\n",
    "            df = df_current\n",
    "\n",
    "        df = df.orderBy(\"date\")\n",
    "\n",
    "        # SMA200 Calculation (Simple Moving Average)\n",
    "        window_spec_200 = Window.orderBy(\"date\").rowsBetween(-199, 0)  # 200-day rolling window\n",
    "        df = df.withColumn(\"SMA200\", avg(col(\"close\")).over(window_spec_200))\n",
    "\n",
    "        # EMA50 Calculation (Exponential Moving Average 50)\n",
    "        window_spec_50 = Window.orderBy(\"date\").rowsBetween(-49, 0)\n",
    "        df = df.withColumn(\"EMA50\", avg(col(\"close\")).over(window_spec_50))\n",
    "\n",
    "        # MACD Calculation (12-day EMA, 26-day EMA, Signal Line)\n",
    "        df = df.withColumn(\"EMA12\", avg(col(\"close\")).over(Window.orderBy(\"date\").rowsBetween(-11, 0)))\n",
    "        df = df.withColumn(\"EMA26\", avg(col(\"close\")).over(Window.orderBy(\"date\").rowsBetween(-25, 0)))\n",
    "        df = df.withColumn(\"MACD\", col(\"EMA12\") - col(\"EMA26\"))\n",
    "        df = df.withColumn(\"MACD_Signal\", avg(col(\"MACD\")).over(Window.orderBy(\"date\").rowsBetween(-8, 0)))\n",
    "\n",
    "        # RSI Calculation (Relative Strength Index - 14)\n",
    "        window_rsi = Window.orderBy(\"date\").rowsBetween(-14, -1)\n",
    "        df = df.withColumn(\"delta\", col(\"close\") - lag(col(\"close\")).over(Window.orderBy(\"date\")))\n",
    "        df = df.withColumn(\"gain\", when(col(\"delta\") > 0, col(\"delta\")).otherwise(lit(0)))\n",
    "        df = df.withColumn(\"loss\", when(col(\"delta\") < 0, -col(\"delta\")).otherwise(lit(0)))\n",
    "        df = df.withColumn(\"avg_gain\", avg(col(\"gain\")).over(window_rsi))\n",
    "        df = df.withColumn(\"avg_loss\", avg(col(\"loss\")).over(window_rsi))\n",
    "        df = df.withColumn(\"RS\", col(\"avg_gain\") / col(\"avg_loss\"))\n",
    "        df = df.withColumn(\"RSI\", 100 - (100 / (1 + col(\"RS\"))))\n",
    "\n",
    "        # Select only relevant columns\n",
    "        df = df.select(\"date\", \"SMA200\", \"EMA50\", \"RSI\", \"MACD\")\n",
    "\n",
    "        # Add 'year' column before filtering**\n",
    "        df = df.withColumn(\"year\", year(col(\"date\")))\n",
    "\n",
    "        # Filter only the correct year's data\n",
    "        df = df.filter(col(\"year\") == year_value)\n",
    "\n",
    "        # Store results in Gold Layer\n",
    "        output_path = f\"/datos/gittba/gittba04/{symbol}_Gold\"\n",
    "        df.write.mode(\"append\").partitionBy(\"year\").parquet(output_path)\n",
    "\n",
    "print(\"Gold Layer Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dbeffa-5834-4db4-b031-6b4994213235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+-------------------+----+\n",
      "|               date|            SMA200|             EMA50|               RSI|               MACD|year|\n",
      "+-------------------+------------------+------------------+------------------+-------------------+----+\n",
      "|2024-01-01 01:00:00| 32026.42679999998| 40620.74779999999| 55.35557511757836| 219.40762820511736|2024|\n",
      "|2024-01-02 01:00:00|32119.436349999978| 40790.42739999999| 58.36250432756507| 245.45769230768929|2024|\n",
      "|2024-01-03 01:00:00| 32201.07754999998| 40936.30819999999| 64.08089243162314| 202.79762820513133|2024|\n",
      "|2024-01-04 01:00:00| 32290.13319999998|        41062.1662| 45.95945821323388| 223.38237179486168|2024|\n",
      "|2024-01-05 01:00:00|32376.636999999984|        41221.7982| 51.27941595302999|   305.839615384597|2024|\n",
      "|2024-01-06 01:00:00|32454.938649999982| 41368.88620000001|  50.7856977747711| 234.10211538460862|2024|\n",
      "|2024-01-07 01:00:00|32524.614299999987|41516.104600000006| 51.19734403397331|  258.7264102564077|2024|\n",
      "|2024-01-08 01:00:00|32609.944899999988|        41707.9282| 54.48864528632875|  395.2418589743611|2024|\n",
      "|2024-01-09 01:00:00| 32687.05239999999| 41881.15260000001|63.100717899667956|  572.0026282051258|2024|\n",
      "|2024-01-10 01:00:00|32767.685199999985|        42099.3994| 64.22845050009995|  772.9601923076916|2024|\n",
      "|2024-01-11 01:00:00|32847.067699999985| 42278.01580000001| 63.13323896815093|  966.6695512820515|2024|\n",
      "|2024-01-12 01:00:00| 32909.64139999999|        42387.7848| 66.09528421899887|   954.108461538468|2024|\n",
      "|2024-01-13 01:00:00|32970.419149999994|42490.473200000015| 52.42015431535244|  835.8301282051325|2024|\n",
      "|2024-01-14 01:00:00|33028.693849999996|        42569.5068| 52.39417503448958|  588.8593589743468|2024|\n",
      "|2024-01-15 01:00:00| 33089.01279999999| 42670.78020000001| 48.25030456121283|  605.5471153845938|2024|\n",
      "|2024-01-16 01:00:00| 33152.34254999999|42788.685200000014|44.299775537326724|  548.9583333333285|2024|\n",
      "|2024-01-17 01:00:00| 33213.29354999999|42887.829800000014| 43.75981410803036| 480.75647435896826|2024|\n",
      "|2024-01-18 01:00:00|33266.845899999986| 42957.28700000001| 49.72899994590189|  352.0212179487062|2024|\n",
      "|2024-01-19 01:00:00| 33319.36004999999| 43035.98840000001| 39.05355677992516| 214.10423076922598|2024|\n",
      "|2024-01-20 01:00:00| 33374.00769999999| 43096.25880000002| 40.59932480669868|-151.50128205128567|2024|\n",
      "+-------------------+------------------+------------------+------------------+-------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- SMA200: double (nullable = true)\n",
      " |-- EMA50: double (nullable = true)\n",
      " |-- RSI: double (nullable = true)\n",
      " |-- MACD: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Gold Layer Parquet for all years\n",
    "df_btcusdt_gold = spark.read.parquet(\"/datos/gittba/gittba04/BTCUSDT_Gold\")\n",
    "\n",
    "# Show the first 50 rows\n",
    "df_btcusdt_gold.show()\n",
    "\n",
    "# Print the schema to verify column types\n",
    "df_btcusdt_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66064502-4d6a-41e8-bb9d-ae3aa90c527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in BTCUSDT_Gold: 1461\n"
     ]
    }
   ],
   "source": [
    "df_gold = spark.read.parquet(\"/datos/gittba/gittba04/BTCUSDT_Gold\")\n",
    "row_count = df_gold.count()\n",
    "\n",
    "print(f\"Total rows in BTCUSDT_Gold: {row_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
